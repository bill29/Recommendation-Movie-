{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định Nghĩa :\n",
    "#     K - Nearest Neighbor là một thuật toán supervised-learning đơn giản nhất \n",
    "#     K-NN được sử dụng để giải quyết cả 2 bài toán của Supervised Learning là Classficiation và Regression \n",
    "#     K-NN là một dạng Instance-base learning ( Memory base learning) Ở đây giải thích rằng độ phực tạp của \n",
    "#     Nó sẽ tăng theo dữ liệu ** cái này để sau khi tìm hiểu kỹ thì viết \n",
    "#     K-NN được coi là một thuật toán lười , được xếp vào loại LAZY LEARNING . \n",
    "#     Lý do là mọi tính toán được thực hiện khi nó cần dự đoán đưa ra kết quả mới \n",
    "# Cách hoạt động : \n",
    "#     K-NN là thuât toán tìm đầu ra dữ liệu mới bằng cách dựa trên thông tin của K phần tử gần nhất với nó \n",
    "#     Không quan tâm đến việc có một vài điểm dữ liệu gần nhất này là nhiễu \n",
    "    \n",
    "#     Trong Hệ gợi ý phim ảnh với lõi của phuơng pháp lọc cộng tác sử dụng K-NN này có nghĩa là : \n",
    "#     Hiểu đơn giản : Chúng ta sẽ tính toán để xác định độ tương đương giữa các ( User-User) hoặc (Movide, Movie)\n",
    "#     Từ đó đưa ra quyết định phim này có được yêu thích không bằng việc tính toán với K User gần nhất , hoặc \n",
    "#     K movie gần nhất "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Về mặt tính toán :\n",
    "    # Việc để xác định để lựa chọn được K phần tử có khoảng cách gần nhau . Ta cần xem xét Chuẩn Norn \n",
    "    # Thường dùng là chuẩn Norn 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lợi Ích và Hạn Chế \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dữ Liệu :\n",
    "    # Bộ dữ liệu này ta có thông tin của 3 loài Hoa Lan Iris setosa, Iris virginica và Iris versicolor...\n",
    "    # Mỗi loại có 50 bông được đo với thông tin chiều dài , chiều rộng của đài hoa, chiều dài, chiều rộng cánh hoa\n",
    "    # Ở đây dữ liệu được lưu với tên là iris , nó có sẵn trong thư viện scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 3\n",
      "Number of data points: 150\n",
      "Sample data from class 0:\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "Sample data  from class 1:\n",
      " [[7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]]\n",
      "Sample data  from class 2:\n",
      " [[6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]]\n"
     ]
    }
   ],
   "source": [
    "# CODE \n",
    "# LOAD DATA , PRINT SAMPLE DATA \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors, datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data # thong tin cua vector voi 4 chi so\n",
    "iris_y = iris.target # Phan loai loai hoa tuong ung chay tu 1-3\n",
    "print('Number of classes:', len(np.unique(iris_y)))\n",
    "print('Number of data points:', len(iris_y))\n",
    "\n",
    "#print(iris)\n",
    "\n",
    "X0 = iris_X[iris_y ==0] # Tong hop cac bong hoa thuoc class 0\n",
    "print('Sample data from class 0:\\n', X0[:10,:])\n",
    "X1 = iris_X[iris_y==1]\n",
    "print('Sample data  from class 1:\\n', X1[:10,:])\n",
    "X2 = iris_X[iris_y==2]\n",
    "print('Sample data  from class 2:\\n', X2[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:  100\n",
      "Test size:  50\n"
     ]
    }
   ],
   "source": [
    "# CODE\n",
    "# SPLIT TRAINING DATA, TEST DATA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris_X, iris_y, test_size=50)\n",
    "# X: data\n",
    "# Y : Target\n",
    "print('Training size: ', len(Y_train))\n",
    "print('Test size: ', len(Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print results for 10 test data points:\n",
      "Predicted labels: \n",
      " [1 1 2 0 1 2 1 1 2 1]\n",
      "Ground truth    : \n",
      " [1 1 2 0 1 2 1 2 2 1]\n"
     ]
    }
   ],
   "source": [
    "# CODE\n",
    "# TRAIN WITH K =2\n",
    "Clf = neighbors.KNeighborsClassifier(n_neighbors=2, p=2) # p =2 , Norn 2 \n",
    "Clf.fit(X_train, Y_train)\n",
    "Y_pred = Clf.predict(X_test)\n",
    "\n",
    "print('Print results for 10 test data points:')\n",
    "print(\"Predicted labels: \\n\", Y_pred[:10]) # predict target\n",
    "print(\"Ground truth    : \\n\", Y_test[:10]) #real target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN(with k =2): 96.00 % \n"
     ]
    }
   ],
   "source": [
    "#CODE \n",
    "# EVALUATION METHOD\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = 100.0 * accuracy_score(Y_test, Y_pred)\n",
    "print('Accuracy of KNN(with k =2): %.2f %% ' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NHAN XET\n",
    "# Ở đây có một điều là khi ta tăng số lượng điểm lân cận được xét từ 2 lên 10 thì tỉ lệ chính xác sẽ cao hơn \n",
    "# Về mặt phương pháp thì 10 hay 20 thì trong số các điểm lân cận đó , nhãn nào được chọn nhiều hơn sẽ được gán !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tối ưu :\n",
    "# Việc một kết quả là 98% hay 94% trong một tập dữ liệu nhỏ như vậy là chưa tốt \n",
    "# Bây giờ chúng ta sẽ nâng cao cách tính toán lên , thay vì trong 10 điểm lân cận xa hay gần đều được bỏ phiếu như nhau \n",
    "# bỏ phiếu ( major voting) bây giờ chúng ta sẽ thêm trọng số để có thể tính toán chính xác \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 10NN (1/distance weights): 98.0\n"
     ]
    }
   ],
   "source": [
    "# CODE \n",
    "clf2 = neighbors.KNeighborsClassifier(n_neighbors = 10, p = 2, weights = 'distance')\n",
    "clf2.fit(X_train, Y_train)\n",
    "Y_pred2 = clf2.predict(X_test)\n",
    "accuracy = 100.0 * accuracy_score(Y_test, Y_pred2)\n",
    "\n",
    "print(\"Accuracy of 10NN (1/distance weights):\", accuracy)\n",
    "\n",
    "# Comment \n",
    "# Ở đây chungs ta thấy rằng : Sklearn cho phép chúng ta đánh trọng số bằng 2 phương pháp đó là \n",
    "# weights = 'distance' có nghĩa là điểm càng gần với điểm test đang xét sẽ được đánh trọng số càng lớn với công thức là \n",
    "# với công thứ 1/distance , điểm càng xa thì trọng số của chúng càng thấp \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nhận xét : \n",
    "# Rõ ràng về mặt lý thuyết việc đánh trọng số là đạt hiệu quả rõ ràng , và trong đa số các lần chạy thì \n",
    "# kết quả của thuật toán K-NN với cơ chế uniform là tốt hơn \n",
    "# Tuy nhiên vẫn tồn tại trường hợp phân chia dữ liệu test và dữ liệu train cho kết quả rất xấu , kết quả rất tốt \n",
    "# ví thế chúng ta phải thử với nhiều cách chia dữ liệu khác nhau , và tính kết quả trung bình "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nhận xét về K-NN\n",
    "# ƯU ĐIỂM \n",
    "# 1 Độ phực tạp của quá trình training =0 ( Có nghĩa là thời gian training bằng 0 mà là lưu trữ dữ liệu trong bộ nhớ)\n",
    "# Việc dự đoán đơn giản\n",
    "# NHƯỢC ĐIỂM \n",
    "# Lưu toàn bộ dữ liệu dẫn đến hiệu năng của thuật toán \n",
    "# Việc tính toàn nằm toàn ở khâu TEST( Thực tế là không học gì ) nếu K được gán giá trị cao sẽ tốn rất nhiều thời gian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sau khi chạy thuật toán K-NN với dữ liệu http://yann.lecun.com/exdb/mnist/ - lượng dữ liệu lớn hơn rất nhiều \n",
    "# Kết quả thu được với 1-NN là 96% khá tốt , thơi gian chạy >700s\n",
    "# K-NN  bị đánh giá là thuật toán gặp vấn đề với bài toán số chiều dữ liệu lớn , số điểm dữ liệu lớn \n",
    "# K-NN bị ảnh hưởng rất lớn bởi nhiễu với các K thấp , giả sử có 1 phần tử chọn Yes , 1 phần tử chọn NO "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
